import os
import cv2
import numpy as np
import uuid
import time

ROOT_PATH = 'OG'
IMAGES_PATH = os.path.join(ROOT_PATH, 'images')
PROCESSED_IMAGES_PATH = os.path.join(ROOT_PATH, 'processed_images')
number_images = 20  # Capture 20 photos in total

# Create the directories for images and processed images if they don't exist
os.makedirs(IMAGES_PATH, exist_ok=True)
os.makedirs(PROCESSED_IMAGES_PATH, exist_ok=True)

cap = cv2.VideoCapture(1)  

# Create a unique folder for this batch of images under 'OG/images'
folder_name = str(uuid.uuid4())[:8]  # Generate random folder name
image_folder_path = os.path.join(IMAGES_PATH, folder_name)
os.makedirs(image_folder_path, exist_ok=True)

# Create a unique folder for this batch of processed images under 'OG/processed_images'
processed_img_folder_path = os.path.join(PROCESSED_IMAGES_PATH, folder_name)
os.makedirs(processed_img_folder_path, exist_ok=True)

# Collect images from the camera feed
for imgnum in range(number_images):
    print('Collecting image {}'.format(imgnum))
    
    ret, frame = cap.read()
    imgname = os.path.join(image_folder_path, f'{str(uuid.uuid1())}.jpg')
    cv2.imwrite(imgname, frame)
    cv2.imshow('frame', frame)
    time.sleep(0.5)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# Image processing on captured images
for filename in os.listdir(image_folder_path):
    if filename.endswith(".jpg"):
        img_path = os.path.join(image_folder_path, filename)
        img = cv2.imread(img_path)

        # Image processing steps
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        noise = cv2.fastNlMeansDenoising(gray)
        noise = cv2.cvtColor(noise, cv2.COLOR_GRAY2BGR)

        kernel = np.ones((7, 7), np.uint8)
        img = cv2.morphologyEx(noise, cv2.MORPH_OPEN, kernel)
        img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])
        img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)

        inv = cv2.bitwise_not(img_output)

        gray = cv2.cvtColor(inv, cv2.COLOR_BGR2GRAY)
        erosion = cv2.erode(gray, kernel, iterations=1)

        img = gray.copy()
        skel = img.copy()
        skel[:, :] = 0
        kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))

        while True:
            eroded = cv2.morphologyEx(img, cv2.MORPH_ERODE, kernel)
            temp = cv2.morphologyEx(eroded, cv2.MORPH_DILATE, kernel)
            temp = cv2.subtract(img, temp)
            skel = cv2.bitwise_or(skel, temp)
            img[:, :] = eroded[:, :]
            if cv2.countNonZero(img) == 0:
                break

        ret, thr = cv2.threshold(skel, 5, 255, cv2.THRESH_BINARY);
        processed_img_path = os.path.join(processed_img_folder_path, f'processed_{filename}')  # Save in the processed images folder
        cv2.imwrite(processed_img_path, thr)


import tensorflow as tf
import json
import numpy as np
from matplotlib import pyplot as plt
import cv2
import imghdr
import matplotlib.pyplot as plt
import numpy as np


data = tf.keras.utils.image_dataset_from_directory("OG/processed_images")

data_iterator = data.as_numpy_iterator()

batch = data_iterator.next()

fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch[1][idx])


data = data.map(lambda x,y: (x/255, y))

scaled_iterator = data.as_numpy_iterator()

scaled_iterator.next()

train_size = int(len(data)*.7)
val_size = int(len(data)*.2)+1
test_size = int(len(data)*1)+1

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size + val_size).take(test_size)

from  tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout

model = Sequential()

model.add(Conv2D(16, (3,3),1, activation ="relu", input_shape=(256,256,3)))
model.add(MaxPooling2D())

model.add(Conv2D(32, (3,3),1, activation ="relu"))
model.add(MaxPooling2D())

model.add(Conv2D(16, (3,3),1, activation ="relu"))
model.add(MaxPooling2D())

model.add(Flatten())

model.add(Dense(256, activation ="relu"))
model.add(Dense(2, activation="softmax"))


model.compile("adam", loss = tf.losses.SparseCategoricalCrossentropy(), metrics=["accuracy"])

model.summary()


hist = model.fit(train, epochs=20, validation_data = val)#, callbacks=[tensorflow_callback])

fig = plt.figure()
plt.plot(hist.history['loss'], color='teal', label='loss')
plt.plot(hist.history['val_loss'], color='orange',label='val_loss')
fig.suptitle('Loss', fontsize=20)
plt.legend(loc="upper left")
plt.show()

fig = plt.figure()
plt.plot(hist.history['accuracy'], color='teal', label='accuracy')
plt.plot(hist.history['val_accuracy'], color='orange',label='val_accuracy')
fig.suptitle('Accuracy', fontsize=20)
plt.legend(loc="upper left")
plt.show()

from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy


pre = Precision()
re = Recall()
acc = BinaryAccuracy()

for batch in test.as_numpy_iterator():
    x,y = batch
    yhat = model.predict(x)
    pre.update_state(y, yhat)
    re.update_state(y, yhat)
    acc.update_state(y, yhat)


print(f'Precision:{pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')

img = cv2.imread("Romsi/roms/59b3d672/processed_28913c4a-f03e-11ee-91ff-160bda49e8a5.jpg")
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.show()    

resize = tf.image.resize(img, (256,256))
plt.imshow(resize.numpy().astype(int))
plt.show()

resize_with_batch = tf.expand_dims(resize, axis=0)

predicted_probabilities = model.predict(resize_with_batch)
predicted_class_index = np.argmax(predicted_probabilities)

print("Predicted class index:", predicted_class_index)

